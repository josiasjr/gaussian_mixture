components = 15
n_init=1
limit_size=10000
spark_table=csv_table
header_schema=dt,hr,vl
sql = with A as (select mc, encode_date(dt) as dd, encode_hour(hr) as hh, toDouble(vl) as vl from csv_table \
		where cd in ('2','10')\
		select mc, collect_list(struct(dd, hh, vl)) from A group by mc
input_files=/tmp/daily
output_info=/user/gmm_offline
